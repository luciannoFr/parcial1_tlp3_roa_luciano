{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fee5ee9",
   "metadata": {},
   "source": [
    "# Examen Parcial n°1 2da Parte - TLP3 - Python para Ciencia de Datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999099d0",
   "metadata": {},
   "source": [
    "**A partir del datasets brindado, realizar los siguientes procedimientos:**\n",
    "\n",
    "* Importar datasets con Pandas.\n",
    "* Explorar los datos con los metodos correspondientes. \n",
    "* Limpieza de los datos (Normalización de datos).\n",
    "* Obtener estadisticas.\n",
    "* Mostrar los datos procesados con graficos utilizando la libreria Matplotlib.\n",
    "* Exportar el contenido a un archivo sqlite utilizando PANDAS.\n",
    "\n",
    "\n",
    "**Importante: Se debe documentar cada procedimiento realizado, siguiendo la siguiente estructura:**\n",
    "\n",
    "1. Celda de Markdown (Documentación)\n",
    "2. Código (Sin comentarios, se debe documentar lo sufiente solo en la celda de markdown).\n",
    "\n",
    "\n",
    "### Criterios de Evaluación:\n",
    "\n",
    "1. No esta permitido el uso de IAs durante el examen. (Desactivar Copilot o cualquier herramienta de IA para autocompletar codigo.)\n",
    "\n",
    "2. Se deben utilizar nombres de variables descriptivos y claros (Utilizar la nomeclatura correspondiente para los nombres de variables).\n",
    "\n",
    "3. Comentarios claros y concisos que expliquen el propósito de cada sección del código en una celda de markdown antes del código.\n",
    "\n",
    "4. Utilizar mensajes de commit descriptivos. (Puedes utilizar la extension CONVENTIONAL COMMIT de VS-CODE).\n",
    "\n",
    "5. Entrega en tiempo y forma (Parciales entregados fuera de hora o con commits pasados el horario de entrega quedará invalidado.)\n",
    "\n",
    "6. Todo el código desarrollado debe ser subido a un repositorio en GitHub (el nombre del repositorio de seguir la siguiente estructura: \n",
    "**parcial1_tlp3_nombre_apellido**).\n",
    "\n",
    "7. Para resolver las actividades se debe insertar casillas de codigo entre cada actividad del cuaderno de Jupyter.\n",
    "\n",
    "8. Deben trabajar con el datasets adjunto.\n",
    "\n",
    "9. Una vez finalizado el examen, los resultados deben quedar guardados debajo de cada celda (NO EJECUTAR LA OPCIÓN \"borrar todas las salidas\").\n",
    "\n",
    "**Importante:** Una vez finalizado el examen, marcar como completado en el classroom."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd91f969",
   "metadata": {},
   "source": [
    "## Actividades: \n",
    "### 1. Importación del Dataset con Pandas\n",
    "\n",
    "En esta sección, se debe utilizar la librería Pandas para cargar el archivo CSV que contiene los datos de VENTAS en un DataFrame.\n",
    "\n",
    "### 2. Exploración Inicial de los Datos\n",
    "\n",
    "A continuación, se deben emplear métodos de Pandas para obtener una visión general del dataset. \n",
    "- 2.1: Visualizar las primeras filas y ultimas.\n",
    "- 2.2: Obtener informacion del df con su metodo correspondiente.\n",
    "- 2.3: Hacer un conteo de valores nulos.\n",
    "\n",
    "### 3. Limpieza y Normalización de los Datos\n",
    "\n",
    "- 3.1. Esta etapa crucial deben aplicar la corrección de diversos errores presentes en el dataset. Se abordarán los valores faltantes (Deben aplicar los metodos que ustedes crean convenientes **(Solo 1)**, por ejemplo: Eliminación de filas, cubrir valores con media, mediana, etc.)\n",
    "- 3.2: La columna Fecha deberan pasarla al tipo datetime con su metodo correspondiente.\n",
    "- 3.3: Corregir las mayusculas en el caso de Nombre y Apellido (Si es que corresponde.)\n",
    "\n",
    "\n",
    "### 4. Obtención de Estadísticas Descriptivas\n",
    "\n",
    "Después de la limpieza, deben hacer lo siguiente: \n",
    "\n",
    "- 4.1: calcular nuevamente las estadísticas descriptivas para observar el impacto del proceso de limpieza en los datos numéricos.\n",
    "- 4.2: Calcular estadísticas específicas por grupo (Agrupar dos columnas).\n",
    "\n",
    "### 5. Visualización de los Datos con Matplotlib\n",
    "\n",
    "En esta sección, deben utilizar la librería Matplotlib para crear **UNA** visualización que permitan comprender mejor los datos de ventas.El grafico es a elección, puede crear **UNO** de los siguientes: histogramas, diagramas de dispersión, gráficos de barras y graficos de torta.\n",
    "\n",
    "### 6. Exportación a Archivo SQLite\n",
    "\n",
    "Finalmente, deben utilizar la funcionalidad de Pandas para guardar el DataFrame procesado en una base de datos SQLite. Deben hacer una conexión y hacer una consulta para ver si los datos fueron cargados correctamente.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d7b4dd",
   "metadata": {},
   "source": [
    "### 1. Importación del Dataset con Pandas\n",
    "\n",
    "En esta sección, se debe utilizar la librería Pandas para cargar el archivo CSV que contiene los datos de VENTAS en un DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d804aabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv(\"ventas.csv\") #se carga el archivo csv con pandas como dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f979ee2",
   "metadata": {},
   "source": [
    "### 2. Exploración Inicial de los Datos\n",
    "\n",
    "A continuación, se deben emplear métodos de Pandas para obtener una visión general del dataset. \n",
    "- 2.1: Visualizar las primeras filas y ultimas.\n",
    "- 2.2: Obtener informacion del df con su metodo correspondiente.\n",
    "- 2.3: Hacer un conteo de valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cf3085a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 105 entries, 0 to 104\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   ID_Venta          105 non-null    int64  \n",
      " 1   Nombre_Cliente    105 non-null    object \n",
      " 2   Apellido_Cliente  105 non-null    object \n",
      " 3   Fecha             105 non-null    object \n",
      " 4   Producto          101 non-null    object \n",
      " 5   Cantidad          105 non-null    int64  \n",
      " 6   Precio_Unitario   92 non-null     float64\n",
      " 7   Total_Venta       92 non-null     float64\n",
      " 8   Metodo_Pago       94 non-null     object \n",
      " 9   Region            100 non-null    object \n",
      "dtypes: float64(2), int64(2), object(6)\n",
      "memory usage: 8.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ID_Venta             0\n",
       "Nombre_Cliente       0\n",
       "Apellido_Cliente     0\n",
       "Fecha                0\n",
       "Producto             4\n",
       "Cantidad             0\n",
       "Precio_Unitario     13\n",
       "Total_Venta         13\n",
       "Metodo_Pago         11\n",
       "Region               5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2.1\n",
    "df.head() #se muestra las primeras filas para ver como estan los datos\n",
    "\n",
    "df.tail() #se muestra las ultimas filas\n",
    "\n",
    "#2.2\n",
    "df.info() #se ve un resumen del df\n",
    "\n",
    "#2.3\n",
    "df.isnull().sum() #conteo de valores nulos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
